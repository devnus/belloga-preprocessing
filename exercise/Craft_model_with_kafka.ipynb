{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4217afd-510c-43d9-b7a7-43756d37fcff",
   "metadata": {},
   "source": [
    "use clova : https://github.com/clovaai/CRAFT-pytorch\n",
    "\n",
    "https://github.com/fcakyon/craft-text-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e900f5a-2adc-4f01-9555-575ef9d3a34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[begin] Preprocessing Start\n",
      "Recived Data\n",
      "Topic: raw-data-upload, Partition: 0, Offset: 0, Key: None, Value: {\"enterpriseId\":\"enterprise-account-id\",\"rawDataId\":1,\"projectId\":1,\"fileUrl\":\"https://belloga-dev-s3-unzip-bucket.s3.ap-northeast-2.amazonaws.com/org/real-final-test-logo-testlogoziptest.zip/kakao-logo.png\",\"fileName\":\"org/real-final-test-logo-testlogoziptest.zip/kakao-logo.png\",\"dataType\":\"OCR\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 14417  100 14417    0     0  96617      0 --:--:-- --:--:-- --:--:--  100k\n",
      "/Users/sybae/Belloga-Preprocessing/lib/python3.10/site-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and will be removed in 0.15. Please access them via the appropriate Weights Enum instead.\n",
      "  warnings.warn(\n",
      "/Users/sybae/Belloga-Preprocessing/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sybae/Belloga-Preprocessing/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced Data\n",
      "{'enterpriseId': 'enterprise-account-id', 'rawDataId': 1, 'fileUrl': 'https://belloga-dev-s3-unzip-bucket.s3.ap-northeast-2.amazonaws.com/org/real-final-test-logo-testlogoziptest.zip/kakao-logo.png', 'projectId': 1, 'fileName': 'org/real-final-test-logo-testlogoziptest.zip/kakao-logo.png', 'dataType': 'OCR', 'boundingBoxInfo': [{'x': [24, 131, 130, 23], 'y': [22, 22, 52, 52]}]}\n",
      "Recived Data\n",
      "Topic: raw-data-upload, Partition: 0, Offset: 1, Key: None, Value: {\"enterpriseId\":\"enterprise-account-id\",\"rawDataId\":2,\"projectId\":1,\"fileUrl\":\"https://belloga-dev-s3-unzip-bucket.s3.ap-northeast-2.amazonaws.com/org/real-final-test-logo-testlogoziptest.zip/naver-logo.png\",\"fileName\":\"org/real-final-test-logo-testlogoziptest.zip/naver-logo.png\",\"dataType\":\"OCR\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16573  100 16573    0     0   135k      0 --:--:-- --:--:-- --:--:--  140k\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecived Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Partition: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Offset: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Key: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat( message\u001b[38;5;241m.\u001b[39mtopic, message\u001b[38;5;241m.\u001b[39mpartition, message\u001b[38;5;241m.\u001b[39moffset, message\u001b[38;5;241m.\u001b[39mkey, message\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m---> 25\u001b[0m produce_info_array \u001b[38;5;241m=\u001b[39m \u001b[43mimage_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m output_json \u001b[38;5;241m=\u001b[39m boundingbox_json_generator(produce_info_array)\n\u001b[1;32m     27\u001b[0m produce_boundingbox(output_json)\n",
      "Cell \u001b[0;32mIn [3], line 52\u001b[0m, in \u001b[0;36mimage_preprocessing\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     49\u001b[0m craft_net \u001b[38;5;241m=\u001b[39m load_craftnet_model(cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# perform prediction\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m prediction_result \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43mcraft_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcraft_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43mrefine_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefine_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43mlow_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43mlong_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1280\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# export detected text regions\u001b[39;00m\n\u001b[1;32m     64\u001b[0m exported_file_paths \u001b[38;5;241m=\u001b[39m export_detected_regions(\n\u001b[1;32m     65\u001b[0m image\u001b[38;5;241m=\u001b[39mimage,\n\u001b[1;32m     66\u001b[0m regions\u001b[38;5;241m=\u001b[39mprediction_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     67\u001b[0m output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m     68\u001b[0m rectify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     69\u001b[0m )\n",
      "File \u001b[0;32m~/Belloga-Preprocessing/lib/python3.10/site-packages/craft_text_detector/predict.py:79\u001b[0m, in \u001b[0;36mget_prediction\u001b[0;34m(image, craft_net, refine_net, text_threshold, link_threshold, low_text, cuda, long_size, poly)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refine_net \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch_utils\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 79\u001b[0m         y_refiner \u001b[38;5;241m=\u001b[39m \u001b[43mrefine_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     score_link \u001b[38;5;241m=\u001b[39m y_refiner[\u001b[38;5;241m0\u001b[39m, :, :, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     81\u001b[0m refinenet_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[0;32m~/Belloga-Preprocessing/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Belloga-Preprocessing/lib/python3.10/site-packages/craft_text_detector/models/refinenet.py:76\u001b[0m, in \u001b[0;36mRefineNet.forward\u001b[0;34m(self, y, upconv4)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, upconv4):\n\u001b[1;32m     75\u001b[0m     refine \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([y\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), upconv4], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m     refine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     aspp1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maspp1(refine)\n\u001b[1;32m     79\u001b[0m     aspp2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maspp2(refine)\n",
      "File \u001b[0;32m~/Belloga-Preprocessing/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Belloga-Preprocessing/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Belloga-Preprocessing/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Belloga-Preprocessing/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Belloga-Preprocessing/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from json import loads\n",
    "from craft_text_detector import Craft\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "from json import dumps\n",
    "import time\n",
    "\n",
    "\n",
    "# topic, broker list\n",
    "consumer = KafkaConsumer('raw-data-upload', \n",
    "                         bootstrap_servers='13.209.250.13:9092',\n",
    "                         enable_auto_commit=True, \n",
    "                         auto_offset_reset='earliest')\n",
    "\n",
    "# consumer list를 가져온다\n",
    "print('[begin] Preprocessing Start')\n",
    "for message in consumer:\n",
    "    print(\"Recived Data\")\n",
    "    print(\"Topic: {}, Partition: {}, Offset: {}, Key: {}, Value: {}\".format( message.topic, message.partition, message.offset, message.key, message.value.decode('utf-8')))\n",
    "    produce_info_array = image_preprocessing(message)\n",
    "    output_json = boundingbox_json_generator(produce_info_array)\n",
    "    produce_boundingbox(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e7200d-98ac-48b6-a022-a34b16ef377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundingbox_json_generator(produce_info_array) :\n",
    "    f = open(\"./outputs/image_text_detection.txt\", 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    bounding_box_info_array = []\n",
    "    for line in lines:\n",
    "        coordinate = line.strip()\n",
    "        coordinate_array =list(map(int, coordinate.split(',')))\n",
    "        x_info = coordinate_array[0::2]\n",
    "        y_info = coordinate_array[1::2]\n",
    "\n",
    "        bounding_box_info = OrderedDict()\n",
    "        bounding_box_info[\"x\"]=x_info\n",
    "        bounding_box_info[\"y\"]=y_info\n",
    "\n",
    "        bounding_box_info_array.append(bounding_box_info)\n",
    "    f.close()\n",
    "\n",
    "    output_json = OrderedDict()\n",
    "\n",
    "    output_json['enterpriseId']= produce_info_array[0]\n",
    "    output_json['rawDataId']= produce_info_array[1]\n",
    "    output_json['fileUrl']= produce_info_array[2]\n",
    "    output_json['projectId'] = produce_info_array[3]\n",
    "    output_json['fileName']= produce_info_array[4]\n",
    "    \n",
    "    output_json['dataType']= \"OCR\"\n",
    "    output_json['boundingBoxInfo']= bounding_box_info_array\n",
    "\n",
    "\n",
    "    output_json = json.dumps(output_json, ensure_ascii=False)\n",
    "    \n",
    "    \n",
    "    return output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a51539-7d64-40e7-9909-8194bb9dc496",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def produce_boundingbox(output_json):\n",
    "    #producer를 할당한다\n",
    "    producer = KafkaProducer(acks=0, compression_type='gzip', bootstrap_servers=['13.209.250.13:9092'],\n",
    "                             value_serializer=lambda x: dumps(x).encode('utf-8'))\n",
    "\n",
    "    #data-preprocessing을 토픽으로 지정하여 데이터를 전송한다\n",
    "    start = time.time()\n",
    "    for i in range(1):\n",
    "        preprocessed_data = json.loads(output_json)\n",
    "        data = preprocessed_data\n",
    "        print(\"Produced Data\")\n",
    "        print(data)\n",
    "        producer.send(\"ocr-data-preprocessing\", value=data)\n",
    "        producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe622ee-f5f2-4378-9063-fe75e08edf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(message): \n",
    "    \n",
    "    msg_value = message.value.decode('utf-8')\n",
    "    msg_json = json.loads(msg_value)\n",
    "    \n",
    "        \n",
    "    # 다운받을 이미지 url\n",
    "    url = msg_json['fileUrl']\n",
    "    # curl 요청\n",
    "    os.system(\"curl \" + url + \" > labelingTarget.jpg\")\n",
    "\n",
    "    #input json을 받아서 각 변수에 담아준다\n",
    "    enterpriseId = msg_json['enterpriseId']\n",
    "    rawDataId = msg_json['rawDataId']\n",
    "    projectId = msg_json['projectId']\n",
    "    fileName = msg_json['fileName']\n",
    "    imageUrl = url\n",
    "    \n",
    "    # set image path and export folder directory\n",
    "    image = './labelingTarget.jpg' # can be filepath, PIL image or numpy array\n",
    "    output_dir = 'outputs/'\n",
    "    \n",
    "    # create a craft instance\n",
    "    craft = Craft(output_dir=output_dir, crop_type=\"poly\", cuda=False)\n",
    "    \n",
    "    # apply craft text detection and export detected regions to output directory\n",
    "    prediction_result = craft.detect_text(image)\n",
    "    \n",
    "    # unload models from ram/gpu\n",
    "    craft.unload_craftnet_model()\n",
    "    craft.unload_refinenet_model()\n",
    "    \n",
    "    # import craft functions\n",
    "    from craft_text_detector import (\n",
    "    read_image,\n",
    "    load_craftnet_model,\n",
    "    load_refinenet_model,\n",
    "    get_prediction,\n",
    "    export_detected_regions,\n",
    "    export_extra_results,\n",
    "    empty_cuda_cache\n",
    "    )\n",
    "    \n",
    "    # read image\n",
    "    image = read_image(image)\n",
    "    \n",
    "    # load models\n",
    "    refine_net = load_refinenet_model(cuda=False)\n",
    "    craft_net = load_craftnet_model(cuda=False)\n",
    "    \n",
    "    # perform prediction\n",
    "    prediction_result = get_prediction(\n",
    "    image=image,\n",
    "    craft_net=craft_net,\n",
    "    refine_net=refine_net,\n",
    "    text_threshold=0.7,\n",
    "    link_threshold=0.4,\n",
    "    low_text=0.4,\n",
    "    cuda=False,\n",
    "    long_size=1280\n",
    "    )\n",
    "    \n",
    "    # export detected text regions\n",
    "    exported_file_paths = export_detected_regions(\n",
    "    image=image,\n",
    "    regions=prediction_result[\"boxes\"],\n",
    "    output_dir=output_dir,\n",
    "    rectify=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # export heatmap, detection points, box visualization\n",
    "    export_extra_results(\n",
    "    image=image,\n",
    "    regions=prediction_result[\"boxes\"],\n",
    "    heatmaps=prediction_result[\"heatmaps\"],\n",
    "    output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # unload models from gpu\n",
    "    empty_cuda_cache()\n",
    "    \n",
    "    producer_info_array = [enterpriseId, rawDataId, imageUrl, projectId, fileName]\n",
    "    return producer_info_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb03057f-acaf-43f5-85c2-e1eacc1f5c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "\n",
    "# admin_client = KafkaAdminClient(\n",
    "#     bootstrap_servers=\"13.209.250.13:9092\", \n",
    "#     client_id='test'\n",
    "# )\n",
    "\n",
    "# topic_list = []\n",
    "# topic_list.append(NewTopic(name=\"ocr-data-preprocessing\", num_partitions=1, replication_factor=1))\n",
    "# admin_client.create_topics(new_topics=topic_list, validate_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca6dc2-592c-4848-8991-086ba132bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from json import loads\n",
    "from craft_text_detector import Craft\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "from json import dumps\n",
    "import time\n",
    "\n",
    "\n",
    "# topic, broker list\n",
    "consumer = KafkaConsumer('raw-data-upload', \n",
    "                         bootstrap_servers='13.209.250.13:9092',\n",
    "                         enable_auto_commit=True, \n",
    "                         auto_offset_reset='earliest')\n",
    "\n",
    "# consumer list를 가져온다\n",
    "print('[begin] Preprocessing Start')\n",
    "for message in consumer:\n",
    "    print(\"Recived Data\")\n",
    "    print(\"Topic: {}, Partition: {}, Offset: {}, Key: {}, Value: {}\".format( message.topic, message.partition, message.offset, message.key, message.value.decode('utf-8')))\n",
    "    produce_info_array = image_preprocessing(message)\n",
    "    output_json = boundingbox_json_generator(produce_info_array)\n",
    "    produce_boundingbox(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e976bb-7d47-4f65-94d1-e9989a5c38dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
